# KV Store实验报告
## 系统框架


### 项目文件

### 测试文件

## 优化与创新
### B+树分裂策略改进
本次`KV Store`实验中需要存储的key是不定长的字符串，且以小长度字符串为主。若以传统的按节点度数进行B+树分裂，在索引存储到文件的过程中，文件结构不好设计。若给每个key分配固定的`512Bytes`大小，会造成节点内部有大量的空间浪费，但低于这个值会使得索引的正确性得不到保证。因此我们小组改进了B+树的分裂策略，给B+树的每个节点分配定长的用于存储key的文件块，当节点写满该块时进行分裂，该策略显著减小了B+树单个节点占用的文件块大小，让B+树的每个节点能尽可能多的存储索引记录，有效降低磁盘io次数。

### B+树写放大
采用改进的分裂策略后，需要为节点中的每个key添加在文件块中的位置信息，若key的长度可以很小，那么这些位置信息也会很多，结果还是导致B+树单个节点过大。因此我们小组对插入的key采取了写放大策略，经参数调试后，每个key值的长度设置为20Byte，这样单个节点的信息约占4KB，并且在bench测试时能获得一个较均衡的读写吞吐量。

### B+树多线程锁添加

由于给的样例中采取的是添加文件锁的形式，那样的话虽然能够保证多线程时的正确性，但是所需要花费的时间开销也是很大的，因而为了能够并发执行时提高程序的正确性，同时也能够保证并行执行的准确性，我们选择采用通过添加结点锁的方式来达到最终的目的。通过一定的规则给节点上读写锁，从而保证系统再在读和写上的正确性，并能够使得我们最终得到正确的结果。由于这样的形式，我们需要给节点增添锁变量，一开始是设想直接在节点内部添加，但是显然这样是行不通的，因为我们的节点要储存在硬盘上。所以考虑再三，我们决定添加一个锁池，通过锁池与节点的对应让节点和内存中锁有一一对应的关系。在有了这样的保证之后，接下来需要做的就是如何进行锁的添加，从而锁的添加协议如下：

对于全部的读操作，在B+树中进行索引的时候，每遍历到一个节点，就对该节点添加读锁，访问结束后读锁释放；

对于全部的写操作，在B+树中进行索引的时候，每遍历到一个节点，就对该节点添加写锁，访问结束后写锁释放，如果在叶节点插入后需要向上分裂，那就对父亲节点添加写锁，访问结束后写锁释放，循环直到再也不能向上分裂为止。

通过[此链接](https://zhuanlan.zhihu.com/p/24800198)，我们能够得知这样的锁协议的正确性，从而能够让我们完成多线程的操作，同时提高我们的运行速率。



## 思考题
### 1. 

### 2. 基于SSD和HDD的键值存储系统⽐基于NVM更需要考虑如何高效地完成IO操作。目前KV对外存读写数据的方式有以下几种，他们对KV的整体吞吐、IO利用率和内存使用率有何差异？

+ 系统调用read、write、fsync：程序与硬盘交互，存在用户缓冲区和内核缓冲区间的过度，系统定时执行fsync指令，从内核缓冲区写入物理设备。在使用fsync指令的时候会产生阻塞，影响KV的整体吞吐；fsync单次可以从内核缓冲区写入一定量的数据，但是fsync还需要更新文件的metadata，需要两次的磁盘IO，IO利用率不高；数据需要同时在用户缓冲区、内核缓冲区备份，内存使用率高。

+ 系统调用mmap、msync：直接建立物理设备中文件和内存的通道，即使用共享内存。调用msync才会将共享内存中的数据落盘，IO利用率较高；但是调用msync同样会产生阻塞，影响KV的整体吞吐；数据只需要在共享内存中备份即可，内存使用率较低。

+ 异步IO框架libaio、io_uring和SPDK：异步IO旨在使应用运行和IO执行成为并行关系，利用高性能的存储设备提升IO利用率。libaio是早期的Linux异步IO库，使用了较多的系统调用，以及产生少量的内存占用。io_uring显著减少了系统调用次数，并省去了一些占用的内存。SPDK则采取了尽可能避免程序陷入管态的情形。总的来说，异步IO框架具有IO利用率高，内存使用率低的优秀特性，能很大程度提升KV的整体吞吐量，会是之后重点使用的IO接口。