# KV Store实验报告
## 系统框架


### 项目文件

### 测试文件

## 优化与创新
### B+树分裂策略改进
本次`KV Store`实验中需要存储的key是不定长的字符串，且以小长度字符串为主。若以传统的按节点度数进行B+树分裂，在索引存储到文件的过程中，文件结构不好设计。若给每个key分配固定的`512Bytes`大小，会造成节点内部有大量的空间浪费，但低于这个值会使得索引的正确性得不到保证。因此我们小组改进了B+树的分裂策略，给B+树的每个节点分配定长的用于存储key的文件块，当节点写满该块时进行分裂，该策略显著减小了B+树单个节点占用的文件块大小，让B+树的每个节点能尽可能多的存储索引记录，有效降低磁盘io次数。

### B+树写放大
采用改进的分裂策略后，需要为节点中的每个key添加在文件块中的位置信息，若key的长度可以很小，那么这些位置信息也会很多，结果还是导致B+树单个节点过大。因此我们小组对插入的key采取了写放大策略，经参数调试后，每个key值的长度设置为20Byte，这样单个节点的信息约占4KB，并且在bench测试时能获得一个较均衡的读写吞吐量。

## 思考题
### 1. 

### 2. 基于SSD和HDD的键值存储系统⽐基于NVM更需要考虑如何高效地完成IO操作。目前KV对外存读写数据的方式有以下几种，他们对KV的整体吞吐、IO利用率和内存使用率有何差异？

+ 系统调用read、write、fsync：程序与硬盘交互，存在用户缓冲区和内核缓冲区间的过度，系统定时执行fsync指令，从内核缓冲区写入物理设备。在使用fsync指令的时候会产生阻塞，影响KV的整体吞吐；fsync单次可以从内核缓冲区写入一定量的数据，但是fsync还需要更新文件的metadata，需要两次的磁盘IO，IO利用率不高；数据需要同时在用户缓冲区、内核缓冲区备份，内存使用率高。

+ 系统调用mmap、msync：直接建立物理设备中文件和内存的通道，即使用共享内存。调用msync才会将共享内存中的数据落盘，IO利用率较高；但是调用msync同样会产生阻塞，影响KV的整体吞吐；数据只需要在共享内存中备份即可，内存使用率较低。

+ 异步IO框架libaio、io_uring和SPDK：异步IO旨在使应用运行和IO执行成为并行关系，利用高性能的存储设备提升IO利用率。libaio是早期的Linux异步IO库，使用了较多的系统调用，以及产生少量的内存占用。io_uring显著减少了系统调用次数，并省去了一些占用的内存。SPDK则采取了尽可能避免程序陷入管态的情形。总的来说，异步IO框架具有IO利用率高，内存使用率低的优秀特性，能很大程度提升KV的整体吞吐量，会是之后重点使用的IO接口。